# Roadmap

Roadmaps are a plan or strategy intended to achieve a particular purpose. They help one see where they are, where they are going, and how to get to their destination. Here is a road map for helping the Harold B. Lee Library transition from the current metadata formats to linked data. 

This road map consists of two types of milestones (or in other words stages): on-going and discrete milestones. Communication, training, and scholarship are milestones that will be on-going throughout the transition from current metadata formats to linked data. Assessment, data update, data conversion, data publication, data production, and evaluation are discrete milestones that have a beginning and end. 

I will now explain each milestone in this road map.

## Assessment

"In order to get where you want to go, you have to start out from where you are" (Merrill, 1989, p. 7).

The first milestone or stage is assessment. We need to assess where we are currently, where we have come from, what has been done, and what is currently being done as it relates to metadata in the library. 

This assessment stage includes diagramming and documenting the full lifecycle of a metadata record from birth to presentation; from creation or copy to the patron as exposed in ScholarSearch and from the main library website. 

This lifecycle captures the processes followed in all the systems we use (e.g. Symphony, ArchivesSpace, CONTENTdm) for creating, importing, maintaining, fixing, and converting records so that they can be used by patrons and staff for information retrieval. 

This lifecycle diagram will help give the library the full picture we need to be able to assess where we currently are and what is currently being done as it relates to metadata and linked data. 

It can help identify pain points in the process or duplication of effort. 
This can illuminate low hanging fruit that if fixed could help improve our existing processes and better prepare us for the transition to linked data.

This entire transition effort needs to be user-focused meaning that we focus on the needs of our users (i.e. students, faculty, BYU community, and staff). Our efforts must be in the service of our users to improve their ability to discover and retrive information.

To help assess and evaluate our success towards our patrons and staff we need to establish how we define, measure, and optimize for success. 
What are the quantitative measures for success?
In addition to quantitative measurements we should also consider how our relationships within the library between staff, departments, and divisions are improved through this transition. 
Is it success if our relationships improve with each other in the library as well as with students, faculty, and the rest of the campus community?
Are we a success if our efforts on this work leaves our community happier than before? (reference to Whats New podcast, episode 10)

Gathering requirements is another key step in this stage. 
What needs do we as a library have? 
What are the needs of our users? 

Needs can be assessed by analyzing usage statistics (e.g. ScholarSearch stats tracker) for better understanding how our collections and items are being accessed and used. 

Conducting user tests is also another way to assess user needs.
This establishes a baseline of data to evaluate how well our efforts improve the experience of library patrons and staff. 

## Metadata Update

Our current metadata records exist in various systems (e.g. ArchivesSpace, CONTENTdm, and SirsiDynix Symphony) and have artifacts from past systems (i.e. RLIN and NOTIS) and past metadata content standards.

This stage is about reconciling and enriching our existing metadata to position us for conversion to linked data. 

This work would include any existing efforts to upgrade metadata so the metadata is complete, correct, consistent, and avoids duplication.
Are there headings that aren't authorizing, data that lacks consistency, or duplicate records?

To prevent getting stuck in this stage we would need to identify and prioritize the upgrade tasks and determine what an acceptable data quality level is that we are trying to achieve. 
What is the acceptable level of upgrade for our metadata?
What reports do we have that can help us identify data upgrade tasks?
Can we measure the number of types of metadata upgrading we need? 

Breaking this work down into categories or groups of metadata (i.e. item format, location, source) will help manage and organize the work to be done in this stage. 
We can start with smaller chunks of metadata to work on (e.g. the local name authorities) to learn best practices and gain experience that can be applied to larger sets of metadata.

Another task in this stage is to add URIs to existing entities. In the MARC records this is accomplished by using the 0 subfield. 
Work will need to be done to see how to best accomplish this step with other metadata formats. 
Work we do in this stage to reconcile entities and assign a URI will ease our transition when we convert to a linked data format. 
This reconcilliation step would utilize various reconciliation services to connect entities in our current metadata records with entities that already exist as linked open data. 
Some sources include LCNAF, VIAF, LCSH, Worldcat identities, and Wikidata.
Where we can't reconcile an entity in our metadata to an existing URI we will need to mint our own local URIs. 

The use of named-entity resolution (NER) is an area to explore to extract out data from descriptive metadata fields in an automated fashion. Extracting these entities helps identify and reconcile entities further in cases where a simply lookup is insufficient.

Our goal would be to automate this upgrade work as much as possible. 
Staff would also be involved in reviewing the upgraded metadata to make sure that any automated workflow is running correctly. 
Where we can't automate tasks successfully we would have staff intervene.

Choosing the best tools and approaches for each upgrade task will be crucial to assist in the automation and review of each upgrade task. 
Example tools and approaches to this work would include MarcEdit (Shieh & Reese, 2015), OpenRefine, programming scripts, and the use of a source control system that gives us the ability to see the history of changes we make to records, revert to previous versions of the metadata record, and see side-by-side diffs of what changes we make to a record. 

## Metadata Conversion

- in parallel (or in addition) to existing systems
- determine tools and workflows
    - source control system
- convert MARC to RDF (BIBFRAME? Schema.org?)
- convert RDF to MARC to check how well our conversion did and improve the conversion process
- progressive conversion
    - map out the discrete sets of data to convert
    - convert a set at a time
    - qa/qc after each conversion
- develop crosswalks between formats
    - BIBFRAME to Schema.org
    - MARC to BIBFRAME
    - MARC to Schema.org + bib
    - ArchivesSpace + EAD
    - CONTENTdm + DC

## Metadata Publication

- ways of publishing
- publisher and consumer of linked data (i.e. pull info down from other sources like Wikipedia and display with local bibliographic/authority metadata)
- Jacob Shelby
- 5 stars of linked data (Tim Berners-Lee)
- integrate with ScholarSearch
    - goal is to improve what and how we show information to patron
    - where can we help improve ScholarSearch data ingestion/transformation process?
- create/experiment with new ways of exploring/browing/searching the data

## Metadata Production

- new workbench/tools/processes
    - use 3rd part tools where they work
    - otherwise will need to develop tools in-house
    - bus/event driven
    - evolve over time
    - could evolve to a de-integrated library system with a common set/vocabulary of data with solid interoperability
- source control
    - diff changes
    - history of changes and revert
- less typing and more lookup and dropdown lists (strings to things)
- helps in system to format data entry appropriately
- strongly typed 
- be able to check/verify the data are valid
- data storage in ILS vs. data model
    - don't need to understand how the ILS is storing the data
    - how and what things can be said

## Evaluation

- reflection and lessons learned
- compare results to assessment outcomes/goals/objectives
- user tests
- did we accomplish what we set out to accomplish?
- did we improve things for the patron and staff?
- Our our relationships with each other in the library and with other interested parties and patrons better than we started?
- Our interested parties happier as an outcome of our efforts?

## Communication

Communication is essential to the success of this transition to linked data. 
The work that will be done to make this transition cannot be accomplished in back doors or by only one or two departments. 
Transitioning current metadata formats to linked data will impact and involve multiple departments and divisions. 
This communication includes conveying the vision and direction of the road map at a macro level as well as working with the right people at each stage to ensure decisions are made with the correct understanding and involvement. 
We can't afford to make assumptions when deciding how to implement the road map without first verifying our assumptions with those that know.
At each stage we will need to make sure to involve the right people
The plans and work of each stage will need to be well documented and shared so that all who are interested can know the status and progress of the work being done. 

## Training

The next core stage in this road map is training. 
The training stage is meant to provide understanding and appreciation for the technology as well as the metadata and cataloging work being done by the library. 
It is not designed to transform catalogers into LIT staff or LIT staff into catalogers but to give a base level of understanding that can be shared among staff. 

Transitioning from the current metadata formats will require IT training for metadata and cataloging personnel. 
This includes learning about:

- web technologies like HTML, CSS, and JavaScript
- XML and XSLT
- different kinds of data models (i.e. flat, e-r, hierarchical, graph)
- linked data and the semantic web including, (but not limited to), RDF, SPARQL, and web ontologies
- Wikidata and Wikipedia
- OpenRefine
- the use of the terminal and Python for data manipulation and scripting

There will also need to be metadata and cataloging training for LIT staff.
This includes learning about:
- the art and science of cataloging
- authority work
- MARC records and their variation and nuance including discussion about serials, bound-with items, series, and electronic items
- cataloging tools such as MarcEdit, OCLC connexion, and SirsiDynix Symphony

This training can be accomplished in a variety of arenas:

- LIT and cataloging forums for library
- Regular tutorial training held monthly or (bi-weekly as necessary)
- Small group or one-on-one training for interested staff

The time commitment for this training would be offered on an as-needed basis and wouldn't take more than 10% of one's time each week. 

## Scholarship

The last on-going stage is Scholarship. 
This refers to outreach and involvement within the scholarly community. 
It includes attending relevant conferences, presenting at conferences, and publishing in monographs and/or journals.

There is also opportunities to reach out to other institutions to learn from their experiences and receive feedback on our work. Some example institutions include

- Local academic institutions in the Mountain West (i.e. U of U, U of Nevada)
- other academic institutions doing linked data efforts (i.e. Stanford, U.C. Davis, Cornell, Harvard, University of Illinois at Urbana-Champaign)
- International institutions and academic libraries
- Library of Congress
- OCLC

This stage would also include joining and participating in professional or standard organizations and commitees. 

- BIBFRAME
- Schema.org and the bibliographic extension (https://bib.schema.org)
- OCLC Project Passage and other linked data-related OCLC efforts
- LD4P
- PCC
- NACO/SACO
- IFLA
- NISO

# Ideas

- Maps to introduce the road map idea/thesis
- Alice in Wonderland and the cat to introduce why/destination/begin with the end in mind
